{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Tuple\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = pd.read_csv('../data/marks_csv/aggregated.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEUTRAL': 0.5019329896907216, 'GOOD': 0.2875, 'BAD': 0.21056701030927835}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_counts = aggregated.output.value_counts().to_dict()\n",
    "_sum = sum(output_counts.values())\n",
    "output_coefficients = {n: v/_sum for n, v in output_counts.items()}\n",
    "output_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def normalize(line: str) -> List[str]:\n",
    "    return [morph.parse(word)[0].normal_form for word in (v.lower() for v in re.findall(r\"('?[а-яА-ЯёЁ][а-яА-ЯёЁ]*(?:-[а-яА-ЯёЁ]+)*'?)\", line))]\n",
    "\n",
    "\n",
    "aggregated['ru_words_normal_form'] = aggregated.input.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "DELIMITER = '_'\n",
    "B_DELIMITER = DELIMITER.encode()\n",
    "\n",
    "def train_phrases(sentences, n, min_count, threshold):\n",
    "    if n < 2:\n",
    "        raise ValueError(\"n < 2\")\n",
    "    \n",
    "    grams = []\n",
    "    transformed_corpus = []\n",
    "    \n",
    "    _words = sentences\n",
    "    for ind in range(n - 1):\n",
    "        gram = Phrases(_words, min_count=min_count, delimiter=B_DELIMITER, threshold=threshold)\n",
    "        grams.append(gram)\n",
    "        _words = gram[_words]\n",
    "        transformed_corpus.append(_words)\n",
    "            \n",
    "    return grams, transformed_corpus\n",
    "\n",
    "grams, transformed_corpus = train_phrases(aggregated.ru_words_normal_form, 5, min_count=10, threshold=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalized_counts:\n",
    "\n",
    "(Количество данного слова в классе / Количество данного слова во всех классах) * (размер класса / сумма размеров все классов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.91 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['NEUTRAL', 'GOOD', 'BAD', 'all_count'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "phrases_by_groups = {name: list() for name in aggregated.output.unique()}\n",
    "all_words = []\n",
    "for index, (words, output) in enumerate(zip(transformed_corpus[-1], aggregated.output)):\n",
    "    phrases_by_groups[output].extend(words)\n",
    "    all_words.extend(words)\n",
    "\n",
    "counts = {name: Counter(values) for name, values in phrases_by_groups.items()}\n",
    "counter_sum = Counter(all_words)\n",
    "\n",
    "normalized_counts = {out_name: {word: number/counter_sum[word]/output_coefficients[out_name] for (word, number) in count.most_common()} for out_name, count in counts.items()}\n",
    "normalized_counts['all_count'] = dict(counter_sum)\n",
    "normalized_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>BAD</th>\n",
       "      <th>all_count</th>\n",
       "      <th>word_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>в</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.99</td>\n",
       "      <td>23633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>и</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>на</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.06</td>\n",
       "      <td>8172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>с</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>8170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>для</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  NEUTRAL  GOOD   BAD  all_count  word_counts\n",
       "0    в     0.99  1.03  0.99      23633            1\n",
       "1    и     1.00  1.05  0.92      16346            1\n",
       "2   на     1.01  0.94  1.06       8172            1\n",
       "3    с     1.00  1.01  0.98       8170            1\n",
       "4  для     1.01  1.07  0.89       5237            1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.DataFrame(normalized_counts)\n",
    "df_res.sort_values('all_count', ascending=False, inplace=True)\n",
    "df_res.index.set_names(['word'], inplace=True)\n",
    "df_res.reset_index(inplace=True)\n",
    "\n",
    "def word_counts(line: str) -> bool:\n",
    "    return len(line.replace(DELIMITER, ' ').split())\n",
    "df_res['word_counts'] = df_res.word.map(word_counts)\n",
    "\n",
    "def round_not_none(value):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    return round(value, 2)\n",
    "df_res.NEUTRAL = df_res.NEUTRAL.apply(round_not_none)\n",
    "df_res.GOOD = df_res.GOOD.apply(round_not_none)\n",
    "df_res.BAD = df_res.BAD.apply(round_not_none)\n",
    "\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv('../data/frequencies/statistical_phrases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.read_csv('../data/frequencies/statistical_phrases.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\toutput\tconfidence\n",
    "result = []\n",
    "for words, output, confidence in zip(transformed_corpus[-1], aggregated.output, aggregated.confidence):\n",
    "    result.append(dict(\n",
    "        input_normal_form_phrases=' '.join(words),\n",
    "        output=output,\n",
    "        confidence=confidence,\n",
    "    ))\n",
    "result = pd.DataFrame(result)[['input_normal_form_phrases', 'output', 'confidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../data/marks_csv/aggregated_normalize_phrases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
