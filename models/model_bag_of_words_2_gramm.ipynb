{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def normalize(line: str) -> List[str]:\n",
    "    return [morph.parse(word)[0].normal_form for word in (v.lower() for v in re.findall(r\"('?[а-яА-ЯёЁ][а-яА-ЯёЁ]*(?:-[а-яА-ЯёЁ]+)*'?)\", line))]\n",
    "\n",
    "def get_n_gramm(words: list, n: int = 2): \n",
    "    return ['_'.join(words[i-n+1:i+1]) for i in range(n - 1, len(words))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7150, 4)\n",
      "(5720, 4) (1430, 4)\n"
     ]
    }
   ],
   "source": [
    "aggregated = pd.read_csv('../data/marks_csv/aggregated_clear.csv', index_col=None)\n",
    "aggregated.drop_duplicates(inplace=True)\n",
    "aggregated['input_normal_form'] = aggregated.input.apply(normalize)\n",
    "aggregated['input_normal_form'] = aggregated.input_normal_form.apply(lambda x: x + get_n_gramm(x, 2))\n",
    "print(aggregated.shape)\n",
    "\n",
    "aggregated_train, aggregated_test = train_test_split(aggregated, test_size=0.2, random_state=42)\n",
    "del aggregated\n",
    "print(aggregated_train.shape, aggregated_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEUTRAL': 0.5047202797202798,\n",
       " 'GOOD': 0.28251748251748254,\n",
       " 'BAD': 0.21276223776223777}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_counts = aggregated_train.output.value_counts().to_dict()\n",
    "_sum = sum(output_counts.values())\n",
    "output_coefficients = {n: v / _sum for n, v in output_counts.items()}\n",
    "output_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NEUTRAL', 'BAD', 'GOOD', 'all_count'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_by_groups = {name: [] for name in aggregated_train.output.unique()}\n",
    "all_words = []\n",
    "\n",
    "for index, row in aggregated_train.iterrows():\n",
    "    words_by_groups[row['output']].extend(row['input_normal_form'])\n",
    "    all_words.extend(row['input_normal_form'])\n",
    "\n",
    "counts = {name: Counter(values) for name, values in words_by_groups.items()}\n",
    "counter_sum = Counter(all_words)\n",
    "\n",
    "normalized_counts = {out_name: {word: number/counter_sum[word]/output_coefficients[out_name] for (word, number) in count.most_common()} for out_name, count in counts.items()}\n",
    "normalized_counts['all_count'] = dict(counter_sum)\n",
    "normalized_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(normalized_counts)\n",
    "words.sort_values('all_count', ascending=False, inplace=True)\n",
    "words.index.set_names(['word'], inplace=True)\n",
    "# words.reset_index(inplace=True)\n",
    "\n",
    "def round_not_none(value):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    return round(value, 2)\n",
    "words.NEUTRAL = words.NEUTRAL.apply(round_not_none)\n",
    "words.GOOD = words.GOOD.apply(round_not_none)\n",
    "words.BAD = words.BAD.apply(round_not_none)\n",
    "\n",
    "words_dict = {word: info.to_dict() for word, info in words.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>output</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.73</td>\n",
       "      <td>155.07</td>\n",
       "      <td>122.81</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176.48</td>\n",
       "      <td>102.80</td>\n",
       "      <td>147.40</td>\n",
       "      <td>BAD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BAD    GOOD  NEUTRAL output predict\n",
       "0   66.73  155.07   122.81   GOOD    GOOD\n",
       "1  176.48  102.80   147.40    BAD     BAD"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_correct_value(values: dict, name: str) -> float:\n",
    "    value = values.get(name)\n",
    "    return value if not pd.isna(value) else 0\n",
    "\n",
    "results = []\n",
    "for _, row in aggregated_test.iterrows():\n",
    "    weights = {'NEUTRAL': 0., 'GOOD': 0., 'BAD': 0.}\n",
    "    for word in row['input_normal_form']:\n",
    "        word_info = words_dict.get(word, {})\n",
    "        weights['NEUTRAL'] += get_correct_value(word_info, 'NEUTRAL')\n",
    "        weights['GOOD'] += get_correct_value(word_info, 'GOOD')\n",
    "        weights['BAD'] += get_correct_value(word_info, 'BAD')\n",
    "    results.append(dict(output=row['output'], predict=sorted(weights.items(), key=lambda x: x[1])[-1][0], **weights))\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[210, 102, 112],\n",
       "       [196, 293, 199],\n",
       "       [ 52,  55, 211]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5006570523793723, 0.4993006993006993, 0.4978366390492928)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='weighted'),\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='micro'),\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='macro'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
