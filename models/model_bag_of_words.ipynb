{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def normalize(line: str) -> List[str]:\n",
    "    return [morph.parse(word)[0].normal_form for word in (v.lower() for v in re.findall(r\"('?[а-яА-ЯёЁ][а-яА-ЯёЁ]*(?:-[а-яА-ЯёЁ]+)*'?)\", line))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7150, 4)\n",
      "(5720, 4) (1430, 4)\n"
     ]
    }
   ],
   "source": [
    "aggregated = pd.read_csv('../data/marks_csv/aggregated_clear.csv', index_col=None)\n",
    "aggregated.drop_duplicates(inplace=True)\n",
    "aggregated['input_normal_form'] = aggregated.input.apply(normalize)\n",
    "print(aggregated.shape)\n",
    "\n",
    "aggregated_train, aggregated_test, _, _ = train_test_split(aggregated, aggregated['output'], test_size=0.2, random_state=42)\n",
    "del aggregated\n",
    "print(aggregated_train.shape, aggregated_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>confidence</th>\n",
       "      <th>input_normal_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>Многорезультатная суперкомпиляция – это метод ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.51</td>\n",
       "      <td>[многорезультатный, суперкомпиляция, это, мето...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input   output  confidence  \\\n",
       "5178  Многорезультатная суперкомпиляция – это метод ...  NEUTRAL        0.51   \n",
       "\n",
       "                                      input_normal_form  \n",
       "5178  [многорезультатный, суперкомпиляция, это, мето...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEUTRAL': 0.5047202797202798,\n",
       " 'GOOD': 0.28251748251748254,\n",
       " 'BAD': 0.21276223776223777}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_counts = aggregated_train.output.value_counts().to_dict()\n",
    "_sum = sum(output_counts.values())\n",
    "output_coefficients = {n: v / _sum for n, v in output_counts.items()}\n",
    "output_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NEUTRAL', 'BAD', 'GOOD', 'all_count'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_by_groups = {name: [] for name in aggregated_train.output.unique()}\n",
    "all_words = []\n",
    "\n",
    "for index, row in aggregated_train.iterrows():\n",
    "    words_by_groups[row['output']].extend(row['input_normal_form'])\n",
    "    all_words.extend(row['input_normal_form'])\n",
    "\n",
    "counts = {name: Counter(values) for name, values in words_by_groups.items()}\n",
    "counter_sum = Counter(all_words)\n",
    "\n",
    "normalized_counts = {out_name: {word: number/counter_sum[word]/output_coefficients[out_name] for (word, number) in count.most_common()} for out_name, count in counts.items()}\n",
    "normalized_counts['all_count'] = dict(counter_sum)\n",
    "normalized_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(normalized_counts)\n",
    "words.sort_values('all_count', ascending=False, inplace=True)\n",
    "words.index.set_names(['word'], inplace=True)\n",
    "# words.reset_index(inplace=True)\n",
    "\n",
    "def round_not_none(value):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    return round(value, 2)\n",
    "words.NEUTRAL = words.NEUTRAL.apply(round_not_none)\n",
    "words.GOOD = words.GOOD.apply(round_not_none)\n",
    "words.BAD = words.BAD.apply(round_not_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>BAD</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>all_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>в</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.03</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>и</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NEUTRAL   BAD  GOOD  all_count\n",
       "word                                \n",
       "в        0.99  0.98  1.03      17450\n",
       "и        1.00  0.92  1.06      12032"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words = pd.read_csv('../data/frequencies/bag_of_words.csv', index_col=0)\n",
    "# words = words[words.all_count > 2]\n",
    "words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = {word: info.to_dict() for word, info in words.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>output</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.03</td>\n",
       "      <td>74.19</td>\n",
       "      <td>68.57</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.26</td>\n",
       "      <td>67.46</td>\n",
       "      <td>70.32</td>\n",
       "      <td>BAD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BAD   GOOD  NEUTRAL output predict\n",
       "0  49.03  74.19    68.57   GOOD    GOOD\n",
       "1  77.26  67.46    70.32    BAD     BAD"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_correct_value(values: dict, name: str) -> float:\n",
    "    value = values.get(name)\n",
    "    return value if not pd.isna(value) else 0\n",
    "\n",
    "results = []\n",
    "for _, row in aggregated_test.iterrows():\n",
    "    weights = {'NEUTRAL': 0., 'GOOD': 0., 'BAD': 0.}\n",
    "    for word in row['input_normal_form']:\n",
    "        word_info = words_dict.get(word, {})\n",
    "        weights['NEUTRAL'] += get_correct_value(word_info, 'NEUTRAL')\n",
    "        weights['GOOD'] += get_correct_value(word_info, 'GOOD')\n",
    "        weights['BAD'] += get_correct_value(word_info, 'BAD')\n",
    "    results.append(dict(output=row['output'], predict=sorted(weights.items(), key=lambda x: x[1])[-1][0], **weights))\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[222,  87, 115],\n",
       "       [206, 235, 247],\n",
       "       [ 55,  30, 233]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[1846,   89,  296],\n",
    "       [ 704, 2325,  866],\n",
    "       [  76,   52, 1506]], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4760775765322739, 0.4825174825174825, 0.48395141463611596)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='weighted'),\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='micro'),\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='macro'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>output</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65.96</td>\n",
       "      <td>63.85</td>\n",
       "      <td>61.28</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>71.99</td>\n",
       "      <td>68.29</td>\n",
       "      <td>62.21</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>54.71</td>\n",
       "      <td>53.44</td>\n",
       "      <td>51.98</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>72.71</td>\n",
       "      <td>69.09</td>\n",
       "      <td>51.46</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>74.88</td>\n",
       "      <td>71.49</td>\n",
       "      <td>57.09</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BAD   GOOD  NEUTRAL output predict\n",
       "14   65.96  63.85    61.28   GOOD     BAD\n",
       "161  71.99  68.29    62.21   GOOD     BAD\n",
       "186  54.71  53.44    51.98   GOOD     BAD\n",
       "306  72.71  69.09    51.46   GOOD     BAD\n",
       "327  74.88  71.49    57.09   GOOD     BAD"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[(results['output'] == 'GOOD') & (results['predict'] == 'BAD')].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
