{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>BAD</th>\n",
       "      <th>all_count</th>\n",
       "      <th>word_counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>в</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.99</td>\n",
       "      <td>23644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>и</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NEUTRAL  GOOD   BAD  all_count  word_counts\n",
       "word                                             \n",
       "в        0.99  1.03  0.99      23644            1\n",
       "и        1.00  1.05  0.92      16356            1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.read_csv('../data/frequencies/statistical_phrases.csv', index_col=0)\n",
    "words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = {word: info.to_dict() for word, info in words.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_normal_form_phrases</th>\n",
       "      <th>output</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>условие термодинамический согласованность имет...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>мишень подтвердить там для модель дополнить пр...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           input_normal_form_phrases   output  confidence\n",
       "0  условие термодинамический согласованность имет...  NEUTRAL        0.92\n",
       "1  мишень подтвердить там для модель дополнить пр...  NEUTRAL        0.90"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_texts = pd.read_csv('../data/marks_csv/aggregated_normalize_phrases.csv', index_col=None)\n",
    "normalize_texts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>output</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.63</td>\n",
       "      <td>62.77</td>\n",
       "      <td>69.09</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.38</td>\n",
       "      <td>81.43</td>\n",
       "      <td>84.49</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BAD   GOOD  NEUTRAL   output predict\n",
       "0  72.63  62.77    69.09  NEUTRAL     BAD\n",
       "1  86.38  81.43    84.49  NEUTRAL     BAD"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_correct_value(values: dict, name: str) -> float:\n",
    "    value = values.get(name)\n",
    "    return value if not pd.isna(value) else 0\n",
    "\n",
    "results = []\n",
    "for _, row in normalize_texts.iterrows():\n",
    "    weights = {'NEUTRAL': 0., 'GOOD': 0., 'BAD': 0.}\n",
    "    for word in row['input_normal_form_phrases'].split():\n",
    "        word_info = words_dict.get(word, {})\n",
    "        weights['NEUTRAL'] += get_correct_value(word_info, 'NEUTRAL')\n",
    "        weights['GOOD'] += get_correct_value(word_info, 'GOOD')\n",
    "        weights['BAD'] += get_correct_value(word_info, 'BAD')\n",
    "    results.append(dict(output=row['output'], predict=sorted(weights.items(), key=lambda x: x[1])[-1][0], **weights))\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1868,   72,  291],\n",
       "       [ 685, 2367,  843],\n",
       "       [  68,   39, 1527]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[1868,   72,  291],\n",
    "       [ 685, 2367,  843],\n",
    "       [  68,   39, 1527]], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7439447803261917, 0.7425257731958763, 0.7412908015341403)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='weighted'),\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='micro'),\n",
    "    f1_score(results['output'].tolist(), results['predict'].tolist(), labels=[\"GOOD\", \"NEUTRAL\", \"BAD\"], average='macro'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>output</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65.34</td>\n",
       "      <td>64.13</td>\n",
       "      <td>61.32</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>71.05</td>\n",
       "      <td>67.27</td>\n",
       "      <td>61.16</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>49.57</td>\n",
       "      <td>48.06</td>\n",
       "      <td>47.31</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>71.90</td>\n",
       "      <td>68.29</td>\n",
       "      <td>50.26</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>69.87</td>\n",
       "      <td>68.13</td>\n",
       "      <td>53.19</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>BAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BAD   GOOD  NEUTRAL output predict\n",
       "14   65.34  64.13    61.32   GOOD     BAD\n",
       "161  71.05  67.27    61.16   GOOD     BAD\n",
       "186  49.57  48.06    47.31   GOOD     BAD\n",
       "306  71.90  68.29    50.26   GOOD     BAD\n",
       "327  69.87  68.13    53.19   GOOD     BAD"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[(results['output'] == 'GOOD') & (results['predict'] == 'BAD')].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аналогичный результат быть получить в эксперимент в который расстояние перенос составлять а число нуклеотидный пара разделять донор и акцептор равняться совершенно неожиданный оказаться результат эксперимент в который изучаться перенос электрон на больший расстояние что составлять нуклеотидный пара разделять донор и акцептор несмотря на то что расстояние перенос в эксперимент почти вдвое большой чем в скорость перенос получить в оказаться на три порядок выше'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_texts.loc[14].input_normal_form_phrases    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
